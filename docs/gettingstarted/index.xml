<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gettingstarteds on Companion</title>
    <link>https://libcompanion.github.io/libCompanion/gettingstarted/index.xml</link>
    <description>Recent content in Gettingstarteds on Companion</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-en</language>
    <copyright>2016-2017 Andreas Sekulski.</copyright>
    <atom:link href="https://libcompanion.github.io/libCompanion/gettingstarted/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Getting Started</title>
      <link>https://libcompanion.github.io/libCompanion/gettingstarted/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://libcompanion.github.io/libCompanion/gettingstarted/</guid>
      <description>

&lt;h1 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h1&gt;

&lt;h2 id=&#34;usage-example&#34;&gt;Usage example&lt;/h2&gt;

&lt;p&gt;Companion must be only configured by his Companion Configuration class.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Creates an empty companion configuration class
Companion *companion = new Companion();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This configuration class specified which image processing implementation should
used. Following components must be initialized.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Callback handling&lt;/li&gt;
&lt;li&gt;Search model&lt;/li&gt;
&lt;li&gt;Image processing&lt;/li&gt;
&lt;li&gt;Companion configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;scenario&#34;&gt;Scenario&lt;/h3&gt;

&lt;p&gt;Following object detection scenario describes all configuration steps how to
use Companion. Detection from two posters from a movie file.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Poster A&lt;/th&gt;
&lt;th&gt;Poster B&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;https://libcompanion.github.io/libCompanion/images/example/poster_left.jpg&#34; alt=&#34;Left poster&#34; title=&#34;Left Poster&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://libcompanion.github.io/libCompanion/images/example/poster_right.jpg&#34; alt=&#34;Right poster&#34; title=&#34;Right poster&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;callbacks&#34;&gt;Callbacks&lt;/h3&gt;

&lt;p&gt;Simple set an result and error handler to an companion configuration class to
obtain results and errors by an running companion execution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;companion-&amp;gt;setResultHandler(resultHandler);
companion-&amp;gt;setErrorHandler(errorHandler);
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;result-handling&#34;&gt;Result Handling&lt;/h4&gt;

&lt;p&gt;To obtain results from Companion an Result or Error Handler is needed to
implement. An result handler must be specified as type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void resultHandler(CALLBACK_RESULT results, cv::Mat source)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Type definition from CALLBACK_RESULT is an vector from Result:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#define CALLBACK_RESULT std::vector&amp;lt;Companion::Model::Result*&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example results are all detected object from an 2D Feature Matching in an
image frame.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://libcompanion.github.io/libCompanion/images/example/result_example.jpg?width=20%&#34; alt=&#34;Detected object&#34; title=&#34;Detected Poster B&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void resultHandler(CALLBACK_RESULT results, cv::Mat source) {
    Companion::Model::Result *result;

    for(size_t i = 0; i &amp;lt; results.size(); i++) {

        // Mark the detected object
        result = results.at(i);
        result-&amp;gt;getModel()-&amp;gt;draw(source)
        ;

        // Draw the id of the detected object
        Companion::Draw::Frame *frame = dynamic_cast&amp;lt;Companion::Draw::Frame*&amp;gt;(result-&amp;gt;getModel());
        cv::putText(source,
                    std::to_string(result-&amp;gt;getId()),
                    frame-&amp;gt;getTopRight(),
                    cv::FONT_HERSHEY_DUPLEX,
                    2,
                    frame-&amp;gt;getColor(),
                    frame-&amp;gt;getThickness());
    }

    cv::cvtColor(source, source, CV_RGB2BGR);
    cv::imshow(&amp;quot;Object detection&amp;quot;, source);
    cv::waitKey(1);
    source.release();
    results.clear();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;error-handling&#34;&gt;Error Handling&lt;/h4&gt;

&lt;p&gt;If an error occurred by an running image processing. Comapnion will thrown an
specific Companion::Error::Code. An specialized error message can be obtain
from his Utility method.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void errorHandler(Companion::Error::Code code) {
    // Obtain detailed error message from code
    std::cout &amp;lt;&amp;lt; Companion::Error::getError(code) &amp;lt;&amp;lt; &amp;quot;\n&amp;quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;search-model&#34;&gt;Search Model&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://libcompanion.github.io/libCompanion/images/example/uml_model.jpg&#34; alt=&#34;Image recognition model&#34; title=&#34;Image Recognition Class&#34; /&gt;&lt;/p&gt;

&lt;p&gt;All search models are implemented from abstract ImageRecognitionModel class
for each image processing. For this 2D object detection operation an
FeatureMatchingModel must be created for all searched models.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Companion::Model::Processing::FeatureMatchingModel* model;
for (int i = 0; i &amp;lt; images.size(); i++) {

    model = new Companion::Model::Processing::FeatureMatchingModel();
    model-&amp;gt;setID(i);
    model-&amp;gt;setImage(cv::imread(images[i], cv::IMREAD_GRAYSCALE));

    if(!companion-&amp;gt;addModel(model)) {
        std::cout &amp;lt;&amp;lt; &amp;quot;Model not added&amp;quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;image-processing&#34;&gt;Image Processing&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://libcompanion.github.io/libCompanion/images/example/uml_imageprocessing.jpg&#34; alt=&#34;Image processing model&#34; title=&#34;Image Processing Class&#34; /&gt;&lt;/p&gt;

&lt;p&gt;All supported image processing operations are implemented from ImageProcessing.
For example a 2D Object Detection with usage from OpenCV 3 feature matching
algorithms.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int type = cv::DescriptorMatcher::BRUTEFORCE_HAMMING;
cv::Ptr&amp;lt;cv::DescriptorMatcher&amp;gt; matcher = cv::DescriptorMatcher::create(type);
// -------------- BRISK CPU FM --------------
cv::Ptr&amp;lt;cv::BRISK&amp;gt; feature = cv::BRISK::create(60);
Companion::Algorithm::ImageRecognition* recognition = new Companion::Algorithm::FeatureMatching(feature, feature, matcher, type, 10, 40, true);
companion-&amp;gt;setProcessing(new Companion::Processing::ObjectDetection(companion, recognition, 0.5));
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;execution&#34;&gt;Execution&lt;/h3&gt;

&lt;p&gt;After all configuration steps from Companion are done execute this configuration
class in a try/catch block. If Companion is missed configured a Companion
Error Code will be thrown.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;try {
    // Execute companion
    companion-&amp;gt;run(ps);
} catch (Companion::Error::Code errorCode) {
    errorHandler(errorCode);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>